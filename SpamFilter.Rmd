---
title: "Filtering Spam Emails via Classification Tree-Based Models"
author: "Andy Nguyen, Michael Wolfe, Joseph Caguioa"
date: "6/10/2020"
output: html_document
---

```{R setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
library(pastecs)
library(rpart)
library(rattle)
library(caret)
library(ggplot2)
library(GGally)
library(itertools)
library(tidyr)
library(tidyverse)
library(dplyr)
library(e1071)
```

## Project Guidelines

Using the “emailDFrp” dataset:

1.	Build and evaluate a tree-based model for predicting “spam”
2.	Plot and analyze the paths through one (or many) of your trees
3.	Explain the parameters involved in “tuning” your model
4.	Which variables were “most” important?
5.	How did you evaluate the “performance” of your model?

NOTE: You should use “split” your data when training your model.

## Objective
Most spam messages can usually be identified in a person's email list through the subject line and sender, but may occassionally require a glimpse of the message contents to provide a more conclusive approach. Spam filters examine these various characteristics of an email before classifying the message and placing it into the inbox of spam folder. 

In this study, a classification tree-based model will be built to predict whether an email message is spam (unwanted) or not spam (wanted) through recursive partitioning.
<br>
<br>

## Data Description
The model will be built using data from the open-source [Apache SpamAssassin Project](https://spamassassin.apache.org/) that contains over 9000 labeled email messages for the purposes of developing spam filters. The original data from the SpamAssassin corpus is in text format and must be processed to quantify the information into a useful format. 


<figure class ="image">
<center>
    <img src = "SpamAssassin+HomePage.png">
    <figcaption id = "Figure 1"> **Figure 1: Apache SpamAssassin Home Page** </figcaption>
</center>
</figure>
<br>
<br>

An email can be separated into the header and the body. The header contains information regarding the date sent, the sender, the subject, the message ID, carbon copy recipients, and additional routing information. This can be understood as the encasing envelope for the message. The body can understood as the actual letter that contains the intended message for the recipient and may contain additional information beyond text such as file attachments.

A number of text mining and statistical analysis approaches can be taken to derive meaningful features from email messages. Such features are the character count within the body content of the email, the number of accompanying file attachments, and wheter "Re:" appears at the start of the subject to denote a reply. In this study, a pre-processed format of the data was provided in a dataframe with 9348 observations and 30 feature variables so the specific details regarding these data processing steps will not be explained further.

```{R load email data}
# Load Data (data.Rda file needs to be in same directory as markdown)
emilDFrp = load("data.Rda")
# Cast data as data frame
emails = data.frame(emailDFrp)
# Remove duplicated emails
emails = distinct(emails)

# Display first and last 10 processed emails from data frame
kable(head(emails, n=10), caption = "Table 1: First 10 Process Emails") %>%
  kable_styling(bootstrap_options = c("striped","hover","responsive")) %>%
  scroll_box(width = "100%", height = "465px")
kable(tail(emails, n=10), caption = "Table 2: Last 10 Processed Emails") %>%
  kable_styling(bootstrap_options = c("striped","hover","responsive")) %>%
  scroll_box(width = "100%", height = "470px")
```
<br>

```{R Data Frame Structure}
# Display Internal Structure of Data Frame
knitr::kable(str(emails), caption = "Table 3: Processed Emails Data Frame Structure and Variable Data Types") %>%
  kable_styling(bootstrap_options = c("striped","hover","responsive"))
```

Duplicate emails were found in the provided data frame and were removed for this analysis. The first and last 10 messages from the processed emails data are provided above respectively in Table 1 and 2. The first 10 messages are a sample of 10 emails that are labled as not spam and the last 10 messages are a sample of 10 emails that are labeled as spam. The structure of the processed emails dataframe now contains a total of 6200 messages and 30 feature variables which is also displayed above. The first 17 features are categorical variables with 2 levels each denoting a boolean value of whether or not the message contains that certain feature. The first feature (isSpam) is the target variable labeling whether or not the email was identified as spam. The last 13 features are numerical variables describing various attributes of the message such as length and number of punctuations present. A full, detailed explanation of each feature in the processed emails dataframe is provided below in Table 3. 

<br>

|   Variable      |      Type    |                                      Definition                                          |
|:--------------- |:------------:|-----------------------------------------------------------------------------------------:|
|isSpam           |logical       |TRUE if email message is spam (target variable).                                          |
|isRe             |logical       |TRUE if "Re:" appears at the start of the subject.                                        |
|numLines         |integer       |Number of lines in the body of the message.                                               | 
|bodyCharCt       |integer       |Number of characters in the body of the message.                                          |
|underscore       |logical       |TRUE if email address in the FROM field of the header contains an underscore.             |
|subExcCt         |integer       |Number of exclamation marks in the subject.                                               |
|subQuesCt        |integer       |Number of question marks in the subject.                                                  |
|numAtt           |integer       |Number of attachments in the message.                                                     |
|priority         |logical       |TRUE if a Priority key is present in the header.                                          |
|numRec           |numeric       |Number of recipients of the message, including CCs.                                       |
|perCaps          |numeric       |Percentage of capitals among all letters in the message body, excluding attachments.      |
|isInReplyTo      |logical       |TRUE if the In-Reply-To key is present in the header.                                     |
|sortedRec        |logical       |TRUE if the recipients' email addresses are sorted.                                       |
|subPunc          |logical       |TRUE if words in the subject have punctuation or numbers embedded in them. (e.g. w!se)    |
|hour             |numeric       |Hour of the day in the Date field.                                                        |
|multipartText    |logical       |TRUE if the MIME type is multipart/text.                                                  |
|hasImages        |logical       |TRUE if the message contains images.                                                      |
|isPGPsigned      |logical       |TRUE if the message contains a PGP signature.                                             |
|perHtML          |numeric       |Percentage of characters in HTML tags in the message body in comparison to all characters.|
|subSpamWords     |logical       |TRUE if the subject contains one of the words in a spam word vector.                      |
|subBlanks        |numeric       |Percentage of blanks in the subject.                                                      |
|noHost           |logical       |TRUE if there is no hostname in the Message-Id key in the header.                         |
|numEnd           |logical       |TRUE if the email sender's address (before the @) ends in a number.                       |
|isYelling        |logical       |TRUE if the subject is all capital letters.                                               |
|forwards         |numeric       |Number of forward symbols in a line of the body. (e.g. >>> xxx contains 3 forwards)       |
|isOrigMsg        |logical       |TRUE if the message body contains the phrase original message.                            |
|isDear           |logical       |TRUE if the message body contains the word "dear".                                        |
|isWrote          |logical       |TRUE if the message contains the phrase "wrote:".                                         |
|avgWordLen       |numeric       |The average length of the words in  a message.                                            |
|numDlr           |numeric       |Number of dollar signs in the message body.                                               |

Table: Table 4: Variable Definition Table

<br>

### Summary Statistics 

The plot shown below in Figure 2 visualizes the class label (True or False) distributions for each of the 17 discrete, categorical variables in the processed emails dataframe, including the target variable "isSpam". Most features are predominately labeled False, indicating that the majority of emails do not contain the described attribute in the message. The only feature with more TRUE values is the "sortedRec" variable, meaning that nearly 90% of emails in the data sort the recipienets' email addresses. 

Most importantly, this figure provides the target variable's stratification levels for the validation scheme when training the classification tree model due to the class imbalance. When holding out a split of the data for testing model performance, the sample will be composed of roughly 30.3% spam emails and 69.7% non-spam emails to ensure that the split is representative of the data as a whole.
<br>

```{R Categorical Variables Visualization, fig.align="center", fig.height=6, fig.width=11.5}
# Initialize an empty dataframe
TFcounts = data.frame(FeatureVariables = character(), TFcounts = integer(), total = integer())
for (col in as.list(enumerate(colnames(emails[,1:17])))){
  TFcounts = rbind(TFcounts, data.frame(FeatureVariables=col$value, TFcounts=table(emails[,col$index]), total=sum(table(emails[,col$index]))))
}
TFcounts$labelpos = ifelse(TFcounts$TFcounts.Var1=="F", (1-(TFcounts$TFcounts.Freq/TFcounts$total))+((TFcounts$TFcounts.Freq/TFcounts$total)/2), 
(TFcounts$TFcounts.Freq/TFcounts$total)/2)

ggplot(data = TFcounts, aes(x = FeatureVariables, y = TFcounts.Freq, fill = TFcounts.Var1)) +
  geom_bar(position="fill", stat = "identity", color="black", width=1.0) +
  scale_y_continuous(labels = scales::percent) +
  geom_text(aes(label = paste0(round((TFcounts.Freq/total)*100,1),"%"),y=labelpos), size = 4) +
labs(title="Percentage of True/False Values per Categorical Variable", x="Categorical Feature Variable", y="Percentage of Values", fill="Class Labels", caption="Figure 2: Plot of Class Label Distribution per Categorical Feature Variable") + 
  theme(plot.title=element_text(size=12, hjust=0.5), plot.caption=element_text(size=11, hjust=0.5), legend.position="top", axis.text.x=element_text(angle=30, hjust=1))
```

The following plot shown below in Figure 3 visualizes the distribution of data points for continuous feature variables in the processed emails data frame. These features have average values below 25 with roughly half the variables having average values around 0. The distribution of the "forwards", "numRec", "perCaps", "perHTML", and "subBlanks" variables also present long right tails; as can be seen with the accumulation of black dots extending past the box (75th percentile) and towards values of 100.

For the features listed in Figure 3, a potential outlier email is highlighted in red that presents with a value of 311 (index 5239) for the number of recipients (numRec). However, this outlier should not be considered as an error since intuition suggests that this email would most likely be spam due to an usually large number of intended recipients. A quick search for this outlier email verifies that it is a spam message, and further suggests that a higher number of recipients may be correlated with a spam email.

<br>

``` {R Box Plot Visualization, fig.align = "center", fig.width = 11.5, fig.height = 6}
continuousVals = pivot_longer(emails[,20:29], cols = colnames(emails[,20:29]), names_to = "FeatureVariables", values_to = "Val")
highlight = continuousVals[which(continuousVals$Val>100),]
ggplot(continuousVals, aes(x = FeatureVariables, y = Val)) +
  geom_boxplot() +
  geom_point(data=highlight, colour="red", size=3) + 
  labs(title = "Data Distribution per Continuous Feature Variable", x = "Continuous Feature Variable", y = "Data Values", caption = "Figure 3: Plot of Data Distribution per Continuous Feature Variable") +
  theme(plot.title = element_text(size=12, hjust=0.5), plot.caption = element_text(size=11, hjust=0.5))
```
<br>
<br>

The last 3 continuous variables are visualized in a correlation matrix due to the longer right tails in their data distributions. The correlation matrix visualization (Figure 4) displays bivariate scatterplots with fitted lines on the bottom left, histograms of each variable along the diagnonal, and corresponding pearson's correlation on the top right for the numLines, bodyChartCt, and numDlr features. The scales for the x and y axis are representative of that particular variable's range of values. There appears to be outliers present in each of these variables with an email having 6319 lines for numLines, 188505 characters for bodyCharCt, and 1977 dollar signs for numDlr. These outlier values are highlighted in red in Figure 4 for easier visualization. 

The outliers for numLines and bodyCharCt appear to come from the same emails (index 4193), but do not seem to be errors since their is no maximum text length restriction for emails sent. The large number of dollar signs indicates an outlier (index 3997) that does seem out of the ordinary, but may be context specific regarding finances. The decision on how to handle these outliers will be further examined when building the model and evaluating if its inclusion affects performance. Furthermore, this figure indicates an extremely high correlation between the numLines and bodyCharCt since both of these features are measurements of message length. The inclusion of both these variables will be further evaluated in model building to evaluate their effects on performance. Note: bodyCharCt seems to be a more informative measurement of message length.

```{R Correlation Matrix, fig.align="center", fig.height=7, fig.width=7, message=FALSE}
fitLine <- function(data, mapping, ...){
  p <- ggplot(data = data, mapping = mapping)  +
    geom_point(alpha=0.3) +
    geom_point(emails[c(3997, 4193),c(18,19,30)], mapping = mapping, color="red", size=2) +
    geom_smooth(method=lm, fill="blue", color="blue", ...)
  p
}
ggpairs(emails[,c(18,19,30)], axisLabels="show", lower=list(continuous=fitLine)) + 
  labs(title="Correlation Matrix of Continuous Variables with Heavy Right-Skewed Distributions", caption="Figure 4: Correlation Matrix of numLines, bodyCharCt, and numDlr") +
  theme(plot.title = element_text(size=12, hjust=0.5), plot.caption = element_text(size=11, hjust=0.5))
```
<br>

### Train-Test Split
The processed emails data frame is split into a training set that contains 70% of the emails and a test set that contains 30% of the emails with stratified sampling to preserve the class distributions of the target variable "isSpam", meaning each data split will contain roughly 70% non-spam emails and 30% spam emails. The training set has 4341 observations and the test set has 1859 observations. 

Following this split, the training and test splits also appear to maintain approximately the same levels of class distributions for the other categorical variables (plot shown in the Appendix) with only slight changes in the thousandth decimal place compared to Figure 2.

The training split will be used to tune hyperparameters in the classification tree model in a k-fold cross validation scheme while the test split will be saved to evaluate the performance of our final model.

```{R Train Test Split}
set.seed(567)
# Stratify Train-Test Split to preserve target variable ("isSpam")
# Class distributions are also nearly preserved with slight changes in the thousandth decimal place
spamStrata = createDataPartition(emails$isSpam, times = 1, p = 0.7, list = F)
train <- emails[spamStrata,]
test <- emails[-spamStrata,]
```


### Impute Missing Values
The processed emails dataframe has 7 feature that contain missing values: subSpamWords has 4, noHost has 1, isYelling has 4, subExcCt has 16, subQuesCt has 16, and subBlanks has 16. The "numRec" feature has an overwhelmingly larger amount of missing values with 147, as highlighted below in red within Figure 5.

The imputation methods will be made based on only the training data split to prevent data leakage. The categorical variables ["subSpamWords", "noHost", "isYelling"] will be imputed via probability based on the distribution frequency of the class labels. The continuous variables will be imputed based on the average/median value of the data points within that respective feature.


```{R Visualize Missing Values, fig.align = "center", fig.width=7, fig.height=7}
# Initialize an empty data frame
missCols = data.frame(FeatureVariables = character(), MissingValues = integer())
for (col in as.list(enumerate(colnames(emails)))){
  missVals = sum(is.na(emails[,col$index]))
  if (missVals > 0) {
    #rbind(missCols, as.list(c(col$value,missVals)))
    missCols = rbind(missCols, data.frame(FeatureVariables = col$value, MissingValues = missVals))
  }
}

ggplot(data = missCols, aes(x=FeatureVariables, y=MissingValues, fill=factor(ifelse(MissingValues>20,"yes","no")))) + 
  geom_bar(stat = "identity") + 
  scale_fill_manual(values = c("yes"="red","no"="grey"), guide = FALSE) +
  labs(title = "Number of Missing Values per Feature Variable", x = "Feature Variable", y = "Missing Values", caption = "Figure 5: Plot of Missing Values per Feature Variable") + 
  theme(plot.title = element_text(size=12, hjust=0.5), plot.caption = element_text(size=11, hjust=0.5))
```
<br>

For the "subExcCt" and "subQuestCt" features, the median value will be used to impute missing values instead of the mean since these variable descriptions indicate an integer value instead of a floating point value. These appears to be the imputation approach as well since the mean values for these variables are close to one (~0.15). An argument can also be made to impute the "numRec" feature with the median value as well due to the influence of the outlier value noted before. However, that outlier does not appear to heavily skew the average and thus the mean value appears to be a representative imputation choice in this case. 

Since the "numRec" also indicates an integer value, the imputed mean value will be rounded to the nearest whole number. In cases where there is an outlier value present that skews the average value out of proportion, the decision to impute by median value is recommended as a more representative value of the data. Since the "subBlanks" feature is a measure of percentage, the mean value is chosen as the imputation method. The mean and median for this variable is roughly the same at about ~13-14%. 

Summary statistics of the data splits following imputation can be examined in the Appendix verifying that missing values no longer exist in the data.

```{R Imputation}
#Continuous Variables in Training set
train$subExcCt = ifelse(is.na(train$subExcCt), median(train$subExcCt,na.rm=T), train$subExcCt)
train$subQuesCt = ifelse(is.na(train$subQuesCt), median(train$subQuesCt,na.rm=T), train$subQuesCt)
train$subBlanks = ifelse(is.na(train$subBlanks), mean(train$subBlanks,na.rm=T), train$subBlanks)
train$numRec = ifelse(is.na(train$numRec), round(mean(train$numRec,na.rm=T)), train$numRec)

#Categorical Variables in Training set
train$subSpamWords = factor(ifelse(is.na(train$subSpamWords), sample(x=factor(c(F,T), labels = c("F","T")), prob=c(table(train$subSpamWords)["F"]/sum(complete.cases(train$subSpamWords)), table(train$subSpamWords)["T"]/sum(complete.cases(train$subSpamWords)))), train$subSpamWords), labels = c("F","T"))

train$noHost = factor(ifelse(is.na(train$noHost), sample(x=factor(c(F,T), labels = c("F","T")), prob=c(table(train$noHost)["F"]/sum(complete.cases(train$noHost)), table(train$noHost)["T"]/sum(complete.cases(train$noHost)))), train$noHost), labels = c("F","T"))

train$isYelling = factor(ifelse(is.na(train$isYelling), sample(x=factor(c(F,T), labels = c("F","T")), prob=c(table(train$isYelling)["F"]/sum(complete.cases(train$isYelling)), table(train$isYelling)["T"]/sum(complete.cases(train$isYelling)))), train$isYelling), labels = c("F","T"))


#Continuous Variables in Test set
test$subExcCt = ifelse(is.na(test$subExcCt), median(train$subExcCt,na.rm=T), test$subExcCt)
test$subQuesCt = ifelse(is.na(test$subQuesCt), median(train$subQuesCt,na.rm=T), test$subQuesCt)
test$subBlanks = ifelse(is.na(test$subBlanks), mean(train$subBlanks,na.rm=T), test$subBlanks)
test$numRec = ifelse(is.na(test$numRec), round(mean(train$numRec,na.rm=T)), test$numRec)

#Categorical Variables in Test set
test$subSpamWords = factor(ifelse(is.na(test$subSpamWords), sample(x=factor(c(F,T), labels = c("F","T")), prob=c(table(train$subSpamWords)["F"]/sum(complete.cases(train$subSpamWords)), table(train$subSpamWords)["T"]/sum(complete.cases(train$subSpamWords)))), test$subSpamWords), labels = c("F","T"))

test$noHost = factor(ifelse(is.na(test$noHost), sample(x=factor(c(F,T), labels = c("F","T")), prob=c(table(train$noHost)["F"]/sum(complete.cases(train$noHost)), table(train$noHost)["T"]/sum(complete.cases(train$noHost)))), test$noHost), labels = c("F","T"))

test$isYelling = factor(ifelse(is.na(test$isYelling), sample(x=factor(c(F,T), labels = c("F","T")), prob=c(table(train$isYelling)["F"]/sum(complete.cases(train$isYelling)), table(train$isYelling)["T"]/sum(complete.cases(train$isYelling)))), test$isYelling), labels = c("F","T"))
```

<br>

## Classification Tree-Based Model
The classification tree will be trained through recursive partitioning on the training data split. This approach builds a decision tree that aims to accurately label the emails by splitting into subpopulations of emails based on threshold values or labels of the independent explanatory variables in the data. The recursive process begins with all emails in the training data labeled according to the target variable (isSpam), a number of splits on different feature criterion will follow based on the inputted model hyperparameters.

### Hyperparameter Tuning
The following hyperparameters were tuned in the classification tree: complexity parameter (cp), the maximum depth of any node in the final tree (maxdepth), the minimum number of observations that must exist in a node for a split to occur (minsplit), and the number of observations in any terminal node (minbucket).

The complexity parameter influences computation time by pruning off splits that do not decrease the overall lack of fit by the cp value. The maximum depth is the length of the tree from root node to terminal node and controls for possible number of splits starting from the root node. The minsplit and minbucket parameters are related by restricting the minimum number of emails that must exist in a node. The difference is that the minsplit uses the parameter value to determine a potential split and minbucket uses the parameter value as a requirement size for a terminal node (bottom of tree).

Vectors of hyperparameter values to be tuned are performed in a grid search fashion to find the values that yield the misclassification rate in the tree. The grid search results are visualized in plots to easily locate optimal hyperparameter values (highlighted in red) that yield the lowest misclassification rate. The optimal values found were 0.002 for cp [Figure 6], 11 for max depth [Figure 7], 40 for min split [Figure 8], and 10 for minbucket [Figure 9]. A max depth of 11 was chosen since there appears to be diminishing returns in error minimization following that value. A minsplit value of 40 and minbucket value of 10 were chosen because they were the highest values that yielded the lowest error. This was done to prevent overcomplex models and promote more efficient computational times. 

```{R Hyperparameter Tuning, fig.align = "center", fig.width=7, fig.height=7}
set.seed(567)
#cp
tune.cp <- tune.rpart(isSpam~., data=train, 
                      cp=c(0.001,0.0015,0.002,0.0025,0.003,0.0035,0.004)) #0.002
plot(tune.cp$performances$cp, tune.cp$performances$error, xlab = "cp", ylab = "Error", col = ifelse(tune.cp$performances$cp==0.002, "red", "black"), type="b", cex=2)
title(main="Performance of Tree vs. cp", sub="Figure 6: Comparison of Classification Tree Model Performance of across different complexity parameter values", cex.sub=0.75)

#maxdepth
tune.maxdepth <- tune.rpart(isSpam~., data=train, 
                            maxdepth=c(1:15)) #11
plot(tune.maxdepth$performances$maxdepth, tune.maxdepth$performances$error, xlab = "Max Depth", ylab = "Error", col = ifelse(tune.maxdepth$performances$maxdepth==11, "red", "black"), type="b", cex=2)
title(main="Performance of Tree vs. Maximum Depth", sub="Figure 7: Comparison of Classification Tree Model Performance of across different maximum depths values", cex.sub=0.75)

#minsplit
tune.minsplit <- tune.rpart(isSpam~., data=train, 
                            minsplit=c(10,20,30,40,50)) #40
plot(tune.minsplit$performances$minsplit, tune.minsplit$performances$error, xlab = "Min Split", ylab = "Error", col = ifelse(tune.minsplit$performances$minsplit==40, "red", "black"), type="b", cex=2)
title(main="Performance of Tree vs. Minimum Split", sub="Figure 8: Comparison of Classification Tree Model Performance of across different minimum splits values", cex.sub=0.75)

#minbucket
tune.minbucket <- tune.rpart(isSpam~., data=train, 
                             minbucket=c(1,5,10,15,20,25,30))
plot(tune.minbucket$performances$minbucket, tune.minbucket$performances$error, xlab = "Min Bucket", ylab = "Error", col = ifelse(tune.minbucket$performances$minbucket==10, "red", "black"), type="b", cex=2)
title(main="Performance of Tree vs. Minimum Bucket", sub="Figure 9: Comparison of Classification Tree Model Performance of across different minimum buckets values", cex.sub=0.75)
```

<br>

### Decision Tree from Recursive Partitioning
The plot of the tuned classification tree model is provided below in Figure 10. The root node at the top contains all 4341 emails in the training data. The first split occurs on the number of forwards with emails having more than 5 forwards predicted to be not spam. A closer look at this specific split shows that 1432 emails have more than 5 forwards; in this specific partition (node 2) 99.5% of emails (1425) are correctly classified while 0.5% of emails (7) are misclassified as not spam. This subpopulation of emails containing more than 5 forwards has the highest percentage of messages that were not spam in the training data.

In the other direction of the split, 2909 emails have 5 or less forwards, but there is a large misclassification rate of 45% so further partitions are required. The following split occurs on the percentage of capitals among all letters in the message body (perCaps) with emails having more than 13% predicted to be spam. In this specific partition (node 7) there are 655 emails, with 86% of them (563) correctly classified while 14% of them (92) are misclassified as spam. Following this path, the next split occurs on the number of lines in the body of the message (numLines) with emails having 9 or less lines predicted to be not spam. There are 51 emails in this partition (node 14), with 80% of them (41) correctly classified while 20% of them (10) are misclassified as not spam. 

In the other direction of this split, 604 emails have more than 9 lines and are predicted to be spam messages. In this specific partition (node 15), 92% of emails (553) are correctly classified while (51) are misclassified as spam. From this partition, the last split of this path occurs on the "isWrote" feature indicating if the message contains the phrase “wrote:”. From these 604 emails, 12 contained the phrase "wrote:" and were all correctly predicted to be not spam. The other 592 emails did not contain the phrase "wrote:" and were predicted to be spam. In this specific partition (node 31), 93.4% of emails (553) were correctly classified while 6.6% (39) were misclassified as spam. This subpopulation of emails in node 31 containing 5 forwards or less, having more than 13% of capitals among all letters in the message body (perCaps), more than 9 lines (numLines), and does not contain the phrase "wrote:" (isWrote) has the highest percentage of messages that are spam in the training data.

Note: The specific values referenced were extracted from the rpartFit1 model output provided in the Appendix under "Recursive Partitioning Decision Paths".

```{R Tree Model, fig.align = "center", fig.width=12, fig.height=10}
set.seed(567)
rpartFit1 = rpart(isSpam ~ ., 
                  data = train, 
                  method = "class", 
                  parms = list(split = "information"), 
                  maxsurrogate = 1,
                  usesurrogate = 2,
                  cp = 0.002,
                  maxdepth = 11,
                  minsplit = 40, 
                  minbucket = 10)
fancyRpartPlot(rpartFit1, main="Decision Tree Graph", cex = 0.7, caption="Figure 10: Plot of Recursive Partitioning Paths in Classification Decision Tree")
```

### Model Performance
```{R Evaluate Performance}
# Source: https://csantill.github.io/RTuningModelParameters/
predictCM = function(model,data,modelType)
{
  pred <-predict(model,data,type=modelType)
  confusionMatrix(pred, reference=data$isSpam,positive='T')
}

predictCM(rpartFit1, train, "class")
predictCM(rpartFit1, test, "class")
```

### Variable Importance
```{R Variable Importance Plot, fig.align="center"}
varImp = data.frame(imp = rpartFit1$variable.importance)
varImp$top = ifelse(varImp$imp>200, TRUE, FALSE)
varImp = varImp %>%
  tibble::rownames_to_column() %>% 
  dplyr::rename("variable" = rowname) %>% 
  dplyr::arrange(imp) %>%
  dplyr::mutate(variable = forcats::fct_inorder(variable))
ggplot2::ggplot(varImp) +
  geom_col(aes(x = variable, y = imp, fill = top),
           col = "black", show.legend = F) +
  coord_flip() +
  labs(title="Feature Importance Plot", y="Information Gain", x="Feature Variables", caption="Figure 11: Plot of Feature Importance based on Information Gain") + 
  theme(plot.title=element_text(size=12, hjust=0.5), plot.caption=element_text(size=11, hjust=0.5), legend.position="top", axis.text.x=element_text(angle=30, hjust=1))
```

## Conclusion


### Appendix
Further exploratory data analysis can be examined in the tables and figures provided below to better understand the data and where specific values mentioned were extracted from.

#### Entire Processed Emails Data Frame
```{R Summary Statistics}
# Display Summary Statistics of Numerical Data Columns
kable(stat.desc(emails[,18:30]), caption = "Summary Statistics of Numerical Variables (All Emails)") %>%
  kable_styling(bootstrap_options = c("striped","responsive")) %>%
  scroll_box(width = "100%", height = "607px")
# Display Summary Statistics of Boolean Data Columns
kable(summary(emails[,1:17]), caption = "Summary Statistics of Categorical Variables (All Emails)") %>%
  kable_styling(bootstrap_options = c("striped","responsive")) %>%
  scroll_box(width = "100%", height = "220px")
```

<br>

#### Training-Test Data Splits
``` {R Summary Statistics following Imputation of Data Splits}
# Training Data
kable(stat.desc(train[,18:30]), caption = "Summary Statistics of Numerical Variables (Training Data)") %>%
  kable_styling(bootstrap_options = c("striped","responsive")) %>%
  scroll_box(width = "100%", height = "615px")
kable(summary(train[,1:17]), caption = "Summary Statistics of Categorical Variables (Training Data)") %>%
  kable_styling(bootstrap_options = c("striped","responsive")) %>%
  scroll_box(width = "100%", height = "177px")

# Display Summary Statistics of Numerical Data Columns
kable(stat.desc(test[,18:30]), caption = "Summary Statistics of Numerical Variables (Test Data)") %>%
  kable_styling(bootstrap_options = c("striped","responsive")) %>%
  scroll_box(width = "100%", height = "615px")
# Display Summary Statistics of Boolean Data Columns
kable(summary(test[,1:17]), caption = "Summary Statistics of Categorical Variables (Test Data)") %>%
  kable_styling(bootstrap_options = c("striped","responsive")) %>%
  scroll_box(width = "100%", height = "177px")
```

```{R Class Distribution Check for Categorical Variables Following Stratified Sample Split, fig.align = "center", fig.width = 11.5, fig.height = 6}
# Initialize an empty dataframe
TFcounts = data.frame(FeatureVariables = character(), TFcounts = integer(), total = integer())
for (col in as.list(enumerate(colnames(train[,1:17])))){
  #print(col$index)
  #print(col$value)
  TFcounts = rbind(TFcounts, data.frame(FeatureVariables=col$value, TFcounts=table(train[,col$index]), total=sum(table(train[,col$index]))))
}
TFcounts$labelpos = ifelse(TFcounts$TFcounts.Var1=="F", (1-(TFcounts$TFcounts.Freq/TFcounts$total))+((TFcounts$TFcounts.Freq/TFcounts$total)/2), 
                           (TFcounts$TFcounts.Freq/TFcounts$total)/2)

ggplot(data = TFcounts, aes(x = FeatureVariables, y = TFcounts.Freq, fill = TFcounts.Var1)) +
  geom_bar(position="fill", stat = "identity", color="black", width=1.0) +
  scale_y_continuous(labels = scales::percent) +
  geom_text(aes(label = paste0(round((TFcounts.Freq/total)*100,1),"%"),y=labelpos), size = 4) +
  labs(title="Percentage of True/False Values per Categorical Variable (Train Split)", x="Categorical Feature Variable", y="Percentage of Values", fill="Class Labels")+#, caption="Plot of Class Label Distribution per Categorical Feature Variable (Training Data)") + 
  theme(plot.title=element_text(size=12, hjust=0.5), plot.caption=element_text(size=11, hjust=0.5), legend.position="top", axis.text.x=element_text(angle=30, hjust=1))

# Initialize an empty dataframe
TFcounts = data.frame(FeatureVariables = character(), TFcounts = integer(), total = integer())
for (col in as.list(enumerate(colnames(test[,1:17])))){
  #print(col$index)
  #print(col$value)
  TFcounts = rbind(TFcounts, data.frame(FeatureVariables=col$value, TFcounts=table(test[,col$index]), total=sum(table(test[,col$index]))))
}
TFcounts$labelpos = ifelse(TFcounts$TFcounts.Var1=="F", (1-(TFcounts$TFcounts.Freq/TFcounts$total))+((TFcounts$TFcounts.Freq/TFcounts$total)/2), 
                           (TFcounts$TFcounts.Freq/TFcounts$total)/2)

ggplot(data = TFcounts, aes(x = FeatureVariables, y = TFcounts.Freq, fill = TFcounts.Var1)) +
  geom_bar(position="fill", stat = "identity", color="black", width=1.0) +
  scale_y_continuous(labels = scales::percent) +
  geom_text(aes(label = paste0(round((TFcounts.Freq/total)*100,1),"%"),y=labelpos), size = 4) +
  labs(title="Percentage of True/False Values per Categorical Variable (Test Split)", x="Categorical Feature Variable", y="Percentage of Values", fill="Class Labels")+#, caption="Plot of Class Label Distribution per Categorical Feature Variable (Test Data)") + 
  theme(plot.title=element_text(size=12, hjust=0.5), plot.caption=element_text(size=11, hjust=0.5), legend.position="top", axis.text.x=element_text(angle=30, hjust=1))
```

#### Recursive Partitioning Decision Paths of Classification Tree-Based Model
``` {R}
rpartFit1
```

#### Exclusion of numLines
``` {R}
#cp
set.seed(567)
tune.cp <- tune.rpart(isSpam~., data=train[,names(train)!="numLines"], 
                      cp=c(0.001,0.0015,0.002,0.0025,0.003,0.0035,0.004)) #0.0015
plot(tune.cp, main = "Performance of Tree vs. cp") 
#maxdepth
set.seed(567)
tune.maxdepth <- tune.rpart(isSpam~., data=train[,names(train)!="numLines"], 
                      maxdepth=c(1:15)) #10/11
plot(tune.maxdepth, main = "Performance of Tree vs. Max Depth")
#minsplit
set.seed(567)
tune.minsplit <- tune.rpart(isSpam~., data=train[,names(train)!="numLines"], 
                            minsplit=c(10,20,30,40,50)) #30
plot(tune.minsplit, main = "Performance of Tree vs. MinSplit")
#minbucket
set.seed(567)
tune.minbucket <- tune.rpart(isSpam~., data=train[,names(train)!="numLines"], 
                            minbucket=c(1,5,10,15,20,25,30)) #20
plot(tune.minbucket, main = "Performance of Tree vs. MinBucket") 

set.seed(567)
rpartFit1 = rpart(isSpam ~ ., 
                  data = train[,names(train)!="numLines"], 
                  method = "class", 
                  parms = list(split = "information"), 
                  maxsurrogate = 1,
                  usesurrogate = 2,
                  cp = 0.0020,
                  maxdepth = 11,
                  minsplit = 40, 
                  minbucket = 10)
predictCM(rpartFit1, train[,names(train)!="numLines"], "class")
predictCM(rpartFit1, test[,names(test)!="numLines"], "class")
```